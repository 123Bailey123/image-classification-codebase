max_epochs: 90

log_interval: 10

use_amp: true # if true, it will train in automatic mixed precision mode

only_evaluate: false # if true, it will only evalute the model on the validation set and exit

auto_resume: true # if true, it will automatically load the checkpoint in the output directory and continue to train

sync_batchnorm: false # if true, it will convert all the batchnorm layers into torch.nn.SyncBatchNorm

accmulated_steps: 1

set_reproducible: false # if true, the training will be set to reproducible (refer to https://pytorch.org/docs/stable/notes/randomness.html)
                        # else torch.backends.cudnn.benchmark will be set to True for largest throughput

data {
    type_: synthetic_data

    image_size: [256,3,224,224]
    target_size: [256]
    device: cuda

    num_classes: 1000
}

model {
    type_: resnet50
    pretrained: false
    load_from: null
}

optimizer {
    type_: CustomSGD
    lr: 0.256
    basic_bs: 256 # we set lr=0.256 for 256 batch size, for other batch sizes we linearly scale the learning rate.
    momentum: 0.875
    dampening: 0
    weight_decay: 3.0517578125e-05 # refer to https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Classification/ConvNets/resnet50v1.5
    nesterov: false
    bn_weight_decay: 0
}

scheduler {
    type_: WarmupCosineAnnealingLR
    T_warmup: 5
    T_max: ${max_epochs}
    eta_min: 0
}

criterion {
    type_: LabelSmoothCrossEntropyLoss
    num_classes: ${data.num_classes}
    epsilon: 0.1
}
